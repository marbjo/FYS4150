\documentclass{emulateapj}
%\documentclass[12pt,preprint]{aastex}

\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{epsfig,floatflt}
\usepackage{hyperref}
\usepackage[toc, page]{appendix}
\usepackage{verbatim, amsmath, amsfonts, amssymb, amsthm}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{float}
\usepackage{xcolor}
\usepackage{color}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage[export]{adjustbox}
\usepackage{calc}

\usepackage{accents}
\newcommand{\dbtilde}[1]{\accentset{\approx}{#1}}
\newcommand{\vardbtilde}[1]{\tilde{\raisebox{0pt}[0.85\height]{$\tilde{#1}$}}}

\usepackage{lipsum}
\usepackage[para]{footmisc}


\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
	backgroundcolor=\color{white}\ttfamily\tiny,   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
	basicstyle=\tiny,        % the size of the fonts that are used for the code \footnotesize,
	breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
	columns=fullflexible,    %no spaces between columns
	keepspaces=true,
	breaklines=true,                 % sets automatic line breaking
	breakatwhitespace=true,
	captionpos=b,                    % sets the caption-position to bottom
	commentstyle=\color{mygreen},    % comment style
	deletekeywords={...},            % if you want to delete keywords from the given language
	escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
	extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
	frame=single,	                   % adds a frame around the code
	keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
	keywordstyle=\color{blue},       % keyword style
	language=Python,                 % the language of the code
	morekeywords={*,...},           % if you want to add more keywords to the set
	%numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
	%numbersep=5pt,                   % how far the line-numbers are from the code
	%numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
	rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
	showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
	showstringspaces=false,          % underline spaces within strings only
	showtabs=false,                  % show tabs within strings adding particular underscores
	stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
	stringstyle=\color{mymauve},     % string literal style
	tabsize=1,	                   % sets default tabsize to 2 spaces
	%title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\begin{document}

\title{Numerical integration - An empirical study of Gaussian quadrature and Monte Carlo}

\author{Bruce Chappell and Markus Bj√∏rklund}

\email{markus.bjorklund@astro.uio.no}

\altaffiltext{1}{Institute of Theoretical Astrophysics, University of
  Oslo, P.O.\ Box 1029 Blindern, N-0315 Oslo, Norway}

\begin{abstract}
In this paper, we apply the Gaussian quadrature and Monte Carlo integration methods for solving the six-dimensional integral arising from the expectation value for the correlation energy between two electrons in a helium atom. The results show that while the brute force Gaussian quadrature error scales downwards with grid points, the improved Gaussian quadrature reduces the error by almost one whole order of magnitude, and converges much much faster (in terms of grid points). It is however slower in terms of run time. The brute force Monte Carlo is very fast, but highly inaccurate. The improved Monte Carlo gives the best result, as it is both the fastest and the most accurate. In summary, when considering run time and accuracy, one would prefer the improved Monte Carlo method, followed by improved Gaussian, brute force Monte Carlo and finally the brute force Gaussian quadrature.

\end{abstract}
\keywords{Numerical integration --- Guassian quadrature --- Monte Carlo methods}

\section{Introduction}
\label{sec:introduction}

In many scientific applications, we encounter the case of multi-dimensional integrals. These are almost always impossible to solve analytically, so we need to employ numerical methods. Traditional integration methods, like Newton-Cotes, often require a lot of mesh points in order to achieve a desired accuracy, thereby drastically increasing the demand for computational power. In the case of multi-dimensional integrals, this demand would be even higher, as we would scale as $N^n$ FLOPS, where N is the number of mesh points and n is the dimension of the integral. Therefore, there is a lot to be gained by finding methods in which we can decrease the amount of FLOPS, while retaining the accuracy. In this paper, we will look at two such methods here, namely Gaussian quadrature and Monte Carlo integration.

The problem in question is that of determining the ground state correlation energy between two electrons in a helium atom. This problem presents a six-dimensional integral, with an analytical solution. The fact that an analytical solution exists will prove as an important benchmark for our algorithms, and thereby sets up a perfect environment for testing the efficiency of different algorithms.

The paper consists of 5 main sections following this one. In the theory section, we provide the fundamental theory for setting up the problem, as well as the theory behind the algorithms used to solve the integral. In the methods section, we present details on the implementation of the algorithms, and the choice of parameters, as well as unit testing. In the results section, we provide the main results, focusing on numerical result, error and run time. We discuss the results in the discussion section, and provide closing thoughts in the conclusions section.

\section{Theory}
\label{sec:method}
Our first assumption is that each electron behaves according to the single-particle wave function for an electron in the hydrogen atom, albeit not normalized, given as

\[
   \psi_{1s}({\bf r}_i)  =   e^{-\alpha r_i},
\]
where
\[
   {\bf r}_i =  x_i {\bf e}_x + y_i {\bf e}_y +z_i {\bf e}_z ,
\]
and
\[
r_i = \sqrt{x_i^2+y_i^2+z_i^2}.
\]

Here, $\alpha$ is a parameter. We fix $\alpha$ as a parameter denoting the charge, and in the case of the helium atom, we have $\alpha = 2$. Our ansatz for the combined wave function is that it is given by the product of the individual wave functions
\[
   \Psi({\bf r}_1,{\bf r}_2)  =   e^{-2 (r_1+r_2)}.
\]
Then, the correlation energy, and the integral we wish to solve, is defined as
\begin{equation}\label{eq:correlationenergy}
   \langle \frac{1}{|{\bf r}_1-{\bf r}_2|} \rangle =
   \int_{-\infty}^{\infty} d{\bf r}_1d{\bf r}_2  e^{-4 (r_1+r_2)}\frac{1}{|{\bf r}_1-{\bf r}_2|}.
\end{equation}
This is a six dimensional integral, and has the closed form analytical solution
\[
\langle \frac{1}{|{\bf r}_1-{\bf r}_2|} \rangle = \frac{5\pi^2}{16^2}
\]

\subsection{Gaussian quadrature}
Our first approach is to integrate using Gaussian quadrature. Gaussian quadrature, unlike Newton-Cotes methods, generally have non-evenly spaced integration points $\{x_0 , x_1 , \dots , x_{N-1}\}$, given by the zeros of an orthogonal polynomial. The integral is then approximated by
\begin{equation}
	I = \int_a^b f(x) dx \approx \sum^N_{i = 1} \omega_i f(x_i),
	\label{eq:quadrature}
\end{equation}
where $\omega_i$ are the integration weights.

\subsubsection{Integration points and weights}
There are N integration points and N integration weights. We must therefore approximate the function with a polynomial of degree $2N-1$, $f(x) \approx P_{2N-1}$ to find them. Gaussian quadrature is exact when integrating a polynomial (up to the same degree), and we get

\begin{align}
	I \approx \int P_{2N-1}(x)dx = \sum^{N-1}_{i=0}P_{2N-1}(x_i) \omega_i.
\end{align}

The idea is to expand this polynomial in terms of some (often known) other polynomial of degree N through polynomial division. The choice of polynomial depends on the integration limits, which sets the scope of the orthogonal polynomial. We use the Legendre polynomial $L_N(x)$ here, which is orthogonal for $x\in [-1,1]$, but the argument is valid for all orthogonal polynomials.
\begin{equation}
	P_{2N-1} = L_N(x)P_{N-1}(x) + Q_{N-1}(x),
\end{equation}
where $Q_{N-1}(x)$ is the remainder from the polynomial division. It can be shown that the weights are given by

\begin{equation}
    w_i = 2\left(\hat{L}^{-1}\right)_{0,i},
\end{equation}
where $\hat{L}$ is the matrix
\begin{equation*}
   \hat{L}=\left(\begin{array} {cccc} L_0(x_0)  & L_1(x_0) &\dots &L_{N-1}(x_0)\\
                                   L_0(x_1)  & L_1(x_1) &\dots &L_{N-1}(x_1)\\
                                   \dots  & \dots &\dots &\dots\\
L_0(x_{N-1})  & L_1(x_{N-1}) &\dots &L_{N-1}(x_{N-1})
\end{array}\right),
\end{equation*}
and the integration points $x_i$ are the zeros of the polynomial $L_N$. For a full derivation, see \cite{Lecture1}. For the general case of limits
\begin{equation}
    \int_a^b f(t) dt,
\end{equation}
one can always perform the mapping $t = \frac{b-a}{2}x + \frac{b+a}{2}$ to obtain

\begin{equation*}
  \int_a^bf(t)dt=\frac{b-a}{2}\int_{-1}^1f\left(\frac{(b-a)x}{2}+\frac{b+a}{2}\right)dx.
\end{equation*}

\subsection{Transformation to spherical coordinates}
Our original integral is not well suited for the use of Legendre polynomials. It would therefore be reasonable to perform a transformation to spherical coordinates, and employ the Laguerre polynomials, which are orthogonal on the interval $[0,\infty)$. The Laguerre polynomials are well suited to solve integrals on the form
\begin{equation}
    \int_0^\infty f(x) e^{-x} dx.
\end{equation}

In spherical coordinates, the new differentials become
\begin{align*}
    d\vec{r}_1d\vec{r}_2 &= r_1^2r_2^2 dr_1dr_2 d\cos(\theta_1)d\cos(\theta_2) d\phi_1d\phi_2 \\
    &= r_1^2r_2^2 dr_1dr_2\sin(\theta_1)\sin(\theta_2)d\theta_1d\theta_2d\phi_1d\phi_2
\end{align*}
and the distance between the electrons is given by
\begin{equation*}
|\vec{r}_1 - \vec{r}_2| = \sqrt{r_1^2 + r_2^2 - 2r_1r_2cos(\beta)},
\end{equation*}
where
\begin{equation*}
cos(\beta) = cos(\theta_1)\cos(\theta_2) + \sin(\theta_1)\sin(\theta_2)\cos(\phi_1 - \phi_2).
\end{equation*}

We introduce the substitution $u = 2\alpha r$, such that $r^2 = \frac{u^2}{4\alpha^2}$ and $dr = \frac{du}{2\alpha}$. Inserting all this, we get the integral
\begin{equation}
    I = \frac{1}{32\alpha^5}\int_0^\pi \int_0^\pi \int_0^{2\pi} \int_0^{2\pi} \int_0^{\infty} \int_0^{\infty} f du_1 du_2 d\phi_1 d\phi_2 d\theta_1 d\theta_2,
\end{equation}
where
\begin{equation}
    f = \frac{u_1^2 u_2^2 sin\left(\theta_1\right) sin\left(\theta_2\right) e^{-\left(u_1+u_2\right)}}{\sqrt{u_1^2 + u_2^2 - 2u_1u_2cos\left(\beta\right)}}.
\end{equation}
with new limits $\theta_{1,2} \in [0,\pi]$, $\phi_{1,2} \in [0,2\pi]$ and $r_{1,2} \in [0,\infty)$ as per usual in spherical coordinates. Thus, it is appropriate to use Laguerre polynomials for the radial part, and Legendre polynomials with a mapping to $[-1,1]$ for the angular parts.

\subsection{Monte Carlo integration}
The idea behind Monte Carlo integration is that we can approximate an integral

\begin{equation} \label{eq:MC}
    \int_a^b f\left(x\right) P\left(x\right) \approx \frac{1}{N}\sum_{i=0}^{N-1} f\left(x_i\right),
\end{equation}
where $x_i$ is drawn from the probability distribution $P\left(x\right)$, and N denotes the number of samples. For the case where there is no known distribution inside the integral, one must choose one, I.E.

\begin{equation}
    \int_a^b f\left(x\right) = \int_a^b \frac{f\left(x\right)}{P\left(x\right)}P\left(x\right) dx \equiv \int_a^b g\left(x\right) P\left(x\right) dx.
\end{equation}
Assuming a uniform distribution,
\begin{equation}
    P_\text{uniform}(x) = \frac{1}{b-a}\theta\left(x-a\right)\theta\left(b-x\right),
\end{equation}
where $\theta$ denotes the Heaviside step function, we get

\begin{equation}
    \int_a^b f(x) dx = \left(b-a\right) \int_a^b f(x) P_\text{uniform}(x) dx.
\end{equation}
In the case of the correlation energy, we have $(a,b) = (-\infty,\infty)$, a 6-dimensional integral and our original integrand as given in equation \ref{eq:correlationenergy}. Thus we need to approximate the limits as $(-\lambda,\lambda)$, and we get

\begin{align*}
    I &= \left(2\lambda\right)^6 \int_{-\lambda}^{\lambda} d{\bf r}_1d{\bf r}_2  e^{-4 (r_1+r_2)}\frac{1}{|{\bf r}_1-{\bf r}_2|} P_\text{uniform}({\bf r}_1, {\bf r}_2) \\
    &= \left(2\lambda\right)^6 \int_{-\lambda}^{\lambda} d{\bf r}_1d{\bf r}_2 f({\bf r}_1, {\bf r}_2) P_\text{uniform}({\bf r}_1, {\bf r}_2)
\end{align*}
Thus, we can apply Monte Carlo integration by the relation in equation \ref{eq:MC}, and obtain that
\begin{equation}
    I \approx \frac{\left(2\lambda\right)^6}{N}\sum_{i=0}^{N-1} f({\bf r}_{1,i}, {\bf r}_{2,i}),
\end{equation}
where $\bf r_i$ is drawn from the uniform distribution (I.E. each variable $x_1$, $x_2$, $y_1$, ...).

\subsection{Importance sampling}
As in the case of the Legendre polynomial for the radial part of the integral, we again face a situation where our sample interval, represented by the uniform distribution, does not fit our integrand very well. Therefore, it would be logical to apply "Importance sampling". Importance sampling is the process of drawing from a distribution that follows the shape of the integrand, or in other words "sampling the important values".

We recognize that our integrand contains an exponential term. Probability is conserved under transformation of variables, so by calling

\begin{equation}
    P(y) = e^{-y}
\end{equation}
our probability density function, and mapping
\begin{equation}
    y(u) = -ln\left(1-u\right),
\end{equation}
we get our new integral variable $y\in [0,\infty)$, and can perform Monte Carlo integration with drawing from the exponential distribution instead. This is done for the radial part which has limits $[0,\infty)$, while the angular part still is drawn from the uniform distribution.

\section{Methods}
\label{sec:methods}
In this section we will describe the methods we utilized to acquire our results.
\subsection{Code}
The code used to acquire the results in this report comes from the C++ program \textbf{\textit{num}}\_\textbf{\textit{int.c++}}. This file executes various numerical integration methods, runs unit tests, and prints results to text files. There is also a python file \textbf{\textit{plot.py}} that is used to put the data into easy to handle Pandas dataframes.

\subsection{Algorithm}
The C++ program [CODE NAME!] solves one integration problem using four different methods: Gauss-Legendre Quadrature, a mix of Gauss-Legendre and Gauss-Laguerre Quadrature which we will call Improved Gaussian Quadrature, Monte-Carlo integration using the uniform distribution, and Monte-Carlo integration using importance sampling.
\subsubsection{Quadrature}
For the less elegant Gaussian Quadrature methods, we use functions \textbf{\textit{gauss}}\_\textbf{\textit{legendre}} and \textbf{\textit{gauss}}\_\textbf{\textit{laguerre}} found in [SITE WHERE FUNCTIONS COME FROM] to calculate the integration points and weights for both Gaussian-Legendre and Improved Gaussian Quadrature. The brute force Gaussian-Legendre Quadrature is done using the following pseudo code.
\begin{lstlisting}[language=c++]
double brute_force(int N, double a, double b){
    double *x = new double [N];
    double *w = new double [N];
    gauss_legendre(a, b, x, w, N);
    for (int i = 0; i < N; i++){
        for (int j = 0; j < N; j++){
          for (int k = 0; k < N; k++){
            for (int l = 0; l < N; l++){
              for (int m = 0; m < N; m++){
                for (int n = 0; n < N; n++){
                  integral += w[i]*w[j]*w[k]*w[l]*w[m]*w[n]
                            * remainder(x[i],x[j],x[k],x[l],x[m],x[n]);
    }}}}}}}
\end{lstlisting}
Here we have integrated over all six spatial Cartesian variables on the interval $[a,b]$ with $N$ integration points. $remainder()$ is the remaining function after dividing out the weight function from the function of interest and the selection of $a$ and $b$ will be discussed in Section \ref{subsec:parameters}. The above method is also used for solving our integral using Improved Gaussian Quadrature. We transform our integral to spherical coordinates and use the  the \textbf{\textit{gauss}}\_\textbf{\textit{laguerre}} function to calculate the integration points and weights for the radial dependency. For the angular dependencies, we use the \textbf{\textit{gauss}}\_\textbf{\textit{legendre}} function to get with weights and integration points for $\theta$ and $\phi$ on the intervals $[0,\pi]$ and $[0,2\pi]$ respectively. We now have a weight and points vector unique to each coordinate type and integrate over the six variables.
\subsubsection{Monte-Carlo}
We used the Mersenne-Twister random number generator, \textbf{\textit{mt19937}}, to generate the random numbers for our distribution sampling. We then implemented the following pseudo code for a brute force approach to Monte-Carlo integration.
\begin{lstlisting}[language=c++]
uniform_real_distribution<double> my_dist(a,b);
MCint = MCintsqr = 0;
for (int i = 1; i <= N; i++){
    x1 = my_dist(generate);
    y1 = my_dist(generate);
    z1 = my_dist(generate);
    x2 = my_dist(generate);
    y2 = my_dist(generate);
    z2 = my_dist(generate);
    fx = whole_function(x1,y1,z1,x2,y2,z2);
    MCint += fx;
    MCintsqr += fx*fx;
}
MCint = MCint*scale / ((double) N);
MCintsqr = MCintsqr*scale*scale / ((double) N);
double var = (MCintsqr - MCint*MCint) / ((double) N);
\end{lstlisting}
Here, the uniform distribution is used to generate all random points when solving. We must scale the resulting values by a factor of $(b-a)$ to account for a change of variables for the uniform distribution from $[0,1]$ to $[a,b]$. To improve this method, we transformed the integral to spherical coordinates where we could exploit the exponential shape of the radial dependency and use the exponential distribution to generate the radial values. For the angular dependencies, we still used a scaled uniform distribution from $[0,\pi]$ and $[0,2\pi]$ for $\theta$ and $\phi$ respectively. The same routine of randomly generating a value for each variable and then solving the function using these values is followed for the spherical case.
\subsection{Parameter Selection}
\label{subsec:parameters}
Since we are using numerical techniques to solve the integral described in [EQUATION-CARTESIAN], we must find a reasonable approximation for infinity. In our code, we have implemented a script to loop over $\lambda$ values until $e^{-2\alpha\lambda} < 1\times10^{-5}$ for $\alpha = 2$. The function described in [EQUATION] is radially symmetric so we will use $-\lambda$ and $\lambda$ for the upper and lower bounds when evaluating in Cartesian coordinates. We also need to handle potential singular points arising from the denominator in [EQUATION-CARTESIAN] and [EQUATION-RADIAL]. In our solution, we chose to ignore points where the denominator is $\leq 10^{-10}$.
\subsection{Unit Tests}
Writing unit tests for this project proved to be slightly challenging. Since we know  the analytical answer to our integral from the start, we are testing our methods each time we run the code and compare it to the analytical answer. In a sense, this makes solving this specific integral a unit test of our methods. The values of the weights and integration points are easily found in tabulated charts for both Laguerre and Legendre quadrature. In our code, we implement two tests to compare the weights and points generated by the \textbf{\textit{gauss}}\_\textbf{\textit{legendre}} and \textbf{\textit{gauss}}\_\textbf{\textit{laguerre}} functions compared to the tabulated values.
\subsection{Parallelization}
FUUUUUUUUUUUUUUCK
\section{Results}
\label{sec:results}
Using our function to find an approximation for infinity, we found reasonable integration limits to be [INT LIMITS]. The Gauss-Legendre Quadrature for varying numbers of integration points is as follows:
\begin{table}[H]
\centering
\begin{tabular}{ |p{1.5cm}||p{1.5cm}|p{1.5cm}|p{1.5cm}|  }
 \hline
 \multicolumn{4}{|c|}{Gaussian-Legendre Quadrature} \\
 \hline
 Integration Points & Integral Value & Absolute Error & Runtime\\
 \hline
 5 & 0.34613906 & 0.79564642 & 0.0006730\\
 10 & 0.11083694 & 0.42501733 & 0.0293350\\
 15 & 0.20963127 & 0.087492507 & 0.3302690 \\
 20 & 0.17162642 & 0.10966315 & 1.7916670 \\
 25 & 0.19037988 & 0.012376866 & 6.8354100\\
 30 & 0.18380124 & 0.046504468 & 20.476816\\
 35 & 0.18946931 & 0.017100542 & 51.388580\\
 \hline
\end{tabular}
\caption{Gaussian-Legendre Quadrature Results}
\label{table:1}
\end{table}
To achieve results accurate to three leading digits of the analytical solution, it took [RESULTS HERE]. This result illustrates the inefficiencies of brute force quadrature. By switching to spherical coordinates and using Laguerre-Quadrature for the radial dependency we were able to obtain better results shown in Table 2:
\begin{table}[H]
\begin{tabular}{ |p{2cm}||p{2cm}|p{2cm}|p{2cm}|  }
 \hline
 \multicolumn{4}{|c|}{Improved Gaussian Quadrature} \\
 \hline
 Integration Points & Integral Value & Absolute Error & Runtime\\
 \hline
 5 & 0.17344965 & 0.10020488 & 0.0019270\\
 10 & 0.18645734 & 0.032725561 & 0.0945780\\
 15 & 0.18975898 & 0.015597842 & 1.0635580\\
 20 & 0.19108178 & 0.0087356352 & 5.9160350\\
 25 & 0.19174074 & 0.0053171840 & 22.829351\\
 30 & 0.19211371 & 0.0033823409 & 67.605018\\
 35 & 0.19234330 & 0.0021913142 & 169.90126\\
 \hline
\end{tabular}
\caption{Improved Gaussian-Quadrature Results}
\label{table:2}
\end{table}
Here, we approach the analytical solution with fewer integration points but at the expense of speed. We then implement Monte-Carlo integration over Cartesian integration boundaries using the uniform distribution to generate our random points.
\begin{table}[H]
\begin{tabular}{ |p{1.5cm}||p{1.5cm}|p{1.5cm}|{p1.5cm}|p{1.5cm}| }
 \hline
 \multicolumn{5}{|c|}{Brute Force Monte-Carlo} \\
 \hline
 Integration Points & Integral Value & Absolute Error & Variance & Runtime\\
 \hline
 10       & 0.0057756332 & 0.97003807  & 2.0627118E-05 & 1.100E-05\\
 100      & 0.15430809   & 0.19950449  & 0.021491537   & 6.000E-05\\
 1000     & 0.14230329   & 0.26178113  & 0.0060039768  & 0.0005110\\
 10000    & 0.46626073   & 1.4187950   & 0.067977321   & 0.0047580\\
 100000   & 0.20297467   & 0.052960428 & 0.0014132859  & 0.0391260\\
 1000000  & 0.21497585   & 0.11521831  & 0.00039684405 & 0.3972480\\
 10000000 & 0.20483706   & 0.062621868 & 3.8399567E-05 & 3.9720560\\
 \hline
\end{tabular}
\caption{Monte-Carlo results using Cartesian Coordinates and Uniform Distribution}
\label{table:3}
\end{table}
These results are much better, both when considering runtime and absolute error. We further fine tune our results by converting to spherical coordinates and sampling from distributions which better fit our data. These results are shown in Table 4.
\begin{table}[H]
\begin{tabular}{ |p{1.5cm}||p{1.5cm}|p{1.5cm}|{p1.5cm}|p{1.5cm}| }
 \hline
 \multicolumn{5}{|c|}{Improved Monte-Carlo} \\
 \hline
 Integration Points & Integral Value & Absolute Error & Variance & Runtime\\
 \hline
 10       & 0.023022455  & 0.88056769    & 0.00014693022 & 1.200E-05\\
 100      & 0.56101114   & 1.9103264     & 0.20718558    & 6.600E-05\\
 1000     & 0.19064793   & 0.010986317   & 0.0025355519  & 0.0006310\\
 10000    & 0.18608869   & 0.034638011   & 8.8177499E-05 & 0.0053960\\
 100000   & 0.18785356   & 0.025482505   & 8.5227310E-06 & 0.0481520\\
 1000000  & 0.19220561   & 0.0029055834  & 9.9038990E-07 & 0.5038370\\
 10000000 & 0.19287860   & 0.00058561729 & 1.0340901E-07 & 4.8266750\\
 \hline
\end{tabular}
\caption{Monte-Carlo results using Spherical Coordinates and Importance Sampling}
\label{table:4}
\end{table}

paralleization comparison



\section{Discussion}
\label{sec:discussion}
-------

\section{Conclusions}
\label{sec:conclusions}
--------


\subsection{Further research}
------

\newpage
\begin{thebibliography}{}

\bibitem{Lecture1}[(Hjorth-Jensen, 2017)]{MHJ} Hjorth-Jensen, Morten \, Aug 23 2017, "Computational Physics Lectures:Numerical integration, from Newton-Cotes quadrature to Gaussian quadrature" , \url{http://compphysics.github.io/ComputationalPhysics/doc/pub/integrate/pdf/integrate-print.pdf}

\bibitem{Lecture2}[(Hjorth-Jensen, 2019)]{MHJ} Hjorth-Jensen, Morten \, Oct 4 2019, "Computational Physics Lectures: Introduction to Monte Carlo methods" , \url{http://compphysics.github.io/ComputationalPhysics/doc/pub/mcint/pdf/mcint-print.pdf}

\bibitem{Project}[(Hjorth-Jensen, 2019)]{MHJ} Hjorth-Jensen, Morten \, Oct 2019, "Project 3"
\url{http://compphysics.github.io/ComputationalPhysics/doc/Projects/2019/Project3/pdf/Project3.pdf}

\end{thebibliography}

\section{Appendix}
All source code, data and figures can be found at the github repository: \url{https://github.com/marbjo/FYS4150/tree/master/Project3}

\end{document}
